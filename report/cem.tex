\section{Cross-Entropy Method (CEM)}

The first algorithm implemented is the \textbf{Cross-Entropy Method (CEM)}.

The initial population parameters are initialised reasonably far from the global optimum, in particular, the mean is uniformly sample in the range [-5, 5] and the variance is uniformly sample in the range [0, 1].

The algorithm has been run for the baseline model, and then trying different population size and elite set ratio, and also with different number of generations.
In Table \ref{tab:cem-param} are shown the different combinations of parameter used.

\begin{figure}[htb]
	\centering
	
	\begin{tabular}{lcccc}
		\toprule
		\textbf{experiment} & \textbf{domain} & \textbf{population} & \textbf{elite} &
		\textbf{generations} \\
		\midrule
		\texttt{baseline 						}	& 100 & 30 		& 0.20 	& 100\\
		\texttt{pop\_size-100 					}	& 100 & 100 	& 0.20 	& 100\\
		\texttt{pop\_size-1000 					}	& 100 & 1000 	& 0.20 	& 100\\
		\texttt{elite-30 						}	& 100 & 30 		& 0.30 	& 100\\
		\texttt{elite-10 						}	& 100 & 30 		& 0.10 	& 100\\
		\texttt{pop\_size-100+elite-30 			}	& 100 & 100 	& 0.30 	& 100\\
		\texttt{pop\_size-100+elite-10 			}	& 100 & 100 	& 0.10 	& 100\\
		\texttt{pop\_size-1000+elite-30 		}	& 100 & 1000 	& 0.30 	& 100\\
		\texttt{pop\_size-1000+elite-10 		}	& 100 & 1000 	& 0.10 	& 100\\
		\texttt{iter-50 						}	& 100 & 30 		& 0.20 	& 50\\
		\texttt{iter-30 						}	& 100 & 30 		& 0.20 	& 30\\
		\texttt{iter-30+elite-10 				}	& 100 & 30 		& 0.10 	& 30\\
		\texttt{iter-50+elite-10 				}	& 100 & 30 	& 0.10 	& 50\\
		\texttt{iter-200+pop\_size-1000+elite-30} 	& 100 & 1000 	& 0.30 	& 200\\	
		\bottomrule
	\end{tabular}
	\captionof{table}{CEM parameters}
	\label{tab:cem-param}
\end{figure}

For all the experiments, the algorithm has been run 3 times for both of test functions. In order to evaluate the performance, for each pair of experiment and test function, the best and the worse fitness for each generation (averaged over 3 runs) has been plotted. 

In Tables \ref{tab:cem-performance-s} and \ref{tab:cem-performance-r} are summarised the results.

\begin{figure}[htb]
	\centering
	
	\begin{tabular}{lccc}
		\toprule
		\textbf{experiment} & \textbf{best fitness} & \textbf{worse fitness} & \textbf{avg run time} \\
		\midrule
		\texttt{baseline 						}	& 408.15 &                408.15 &                 0.36 sec \\
		\texttt{pop\_size-100 					}	&   76.19 &                 76.31 &                 0.41 sec \\
		\texttt{pop\_size-1000 					}	&     0.0 &                   0.0 &                 0.89 sec \\
		\texttt{elite-30 						}	& 353.41 &                353.41 &                 0.34 sec \\
		\texttt{elite-10 						}	& 549.93 &                549.93 &                 0.34 sec \\
		\texttt{pop\_size-100+elite-30 			}	&   39.73 &                 40.13 &                 0.38 sec \\
		\texttt{pop\_size-100+elite-10 			}	&  168.58 &                168.58 &                 0.38 sec \\
		\texttt{pop\_size-1000+elite-30 		}	&     0.0 &                   0.0 &                 0.88 sec \\
		\texttt{pop\_size-1000+elite-10 		}	&     0.0 &                   0.0 &                 0.88 sec \\
		\texttt{iter-50 						}	& 365.66 &                365.69 &                 0.33 sec \\
		\texttt{iter-30 						}	& 405.81 &                407.39 &                 0.32 sec \\
		\texttt{iter-30+elite-10 				}	& 606.47 &                606.48 &                 0.33 sec \\
		\texttt{iter-50+elite-10 				}	& 591.32 &                591.32 &                 0.43 sec \\
		\texttt{iter-200+pop\_size-1000+elite-30} 	&     0.0 &                   0.0 &                 1.39 sec \\	
		\bottomrule
	\end{tabular}
	\captionof{table}{Sphere CEM performance}
	\label{tab:cem-performance-s}
\end{figure}

\begin{figure}[htb]
	\centering
	
	\begin{tabular}{lccc}
		\toprule
		\textbf{experiment} & \textbf{best fitness} & \textbf{worse fitness} & \textbf{avg run time} \\
		\midrule
		\texttt{baseline 						}	&  917.88 &                917.88 &                 0.56 sec \\
		\texttt{pop\_size-100 					}	&  372.42 &                372.93 &                 0.62 sec \\
		\texttt{pop\_size-1000 					}	&  340.85 &                 603.9 &                 1.27 sec \\
		\texttt{elite-30 						}	&  873.88 &                 873.9 &                 0.55 sec \\
		\texttt{elite-10 						}	&  1268.29 &               1268.29 &                 0.55 sec \\
		\texttt{pop\_size-100+elite-30 			}	&  314.37 &                316.53 &                  0.6 sec \\
		\texttt{pop\_size-100+elite-10 			}	&  559.49 &                 559.5 &                  0.6 sec \\
		\texttt{pop\_size-1000+elite-30 		}	&  604.86 &               1016.53 &                 1.27 sec \\
		\texttt{pop\_size-1000+elite-10 		}	&  94.1 &                 147.3 &                 1.24 sec \\
		\texttt{iter-50 						}	&  916.63 &                917.04 &                 0.53 sec \\
		\texttt{iter-30 						}	&  975.49 &                997.92 &                 0.53 sec \\
		\texttt{iter-30+elite-10 				}	& 1228.54 &               1228.58 &                 0.54 sec \\
		\texttt{iter-50+elite-10 				}	& 1276.75 &               1276.75 &                  0.7 sec \\
		\texttt{iter-200+pop\_size-1000+elite-30} 	&   33.64 &                 35.85 &                 1.97 sec \\
		\bottomrule
	\end{tabular}
	\captionof{table}{Rastrigin CEM performance}
	\label{tab:cem-performance-r}
\end{figure}


(c) Try . What is the minimum number of gener- ations that you can obtain a solution close enough to the global optimum?
